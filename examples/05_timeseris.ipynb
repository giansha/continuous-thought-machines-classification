{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a72c0e",
   "metadata": {},
   "source": [
    "# The Continuous Thought Machine – Tutorial 04: Parity [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SakanaAI/continuous-thought-machines/blob/main/examples/04_parity.ipynb) [![arXiv](https://img.shields.io/badge/arXiv-2505.05522-b31b1b.svg)](https://arxiv.org/abs/2505.05522)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05cf27b",
   "metadata": {},
   "source": [
    "### Parity\n",
    "\n",
    "The parity of a binary sequence, given by the sign of the product of its elements, can reasonably be predicted by an RNN when the data is fed sequentially - the model need only maintain an internal state, flipping a ‘switch’ whenever a negative number is encountered. When the entire sequence is provided at once, however, the task is significantly more challenging.\n",
    "\n",
    "In Section 8 of the [technical report](https://arxiv.org/pdf/2505.05522), we showcase how a CTM can be trained to do exactly this. In particular, we input the CTM with a binary sequence, and train the model to predict the cumulative parity at each position along the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbffa93",
   "metadata": {},
   "source": [
    "### Tutorial Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2bbea",
   "metadata": {},
   "source": [
    "In this tutorial, we walk through how we trained the CTM, using sequences of length 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272f18",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257dbd3",
   "metadata": {},
   "source": [
    "In addition to installing some dependencies, we also clone the CTM repo (assuming this tutorial is being run in Colab), so that we can access the base CTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab57a96",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "24ffe416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.097442Z",
     "start_time": "2025-08-03T14:38:33.908557Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append(\"./continuous-thought-machines\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "# import argparse\n",
    "import os\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# From CTM repo\n",
    "from models.ctm import ContinuousThoughtMachine\n",
    "from models.modules import CustomRotationalEmbedding1D, TemporalBackbone\n",
    "\n",
    "from data.data_factory import data_provider"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ctm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\Anaconda\\envs\\ctm\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "82620e4e",
   "metadata": {},
   "source": [
    "Set a seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "id": "604415b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.237039Z",
     "start_time": "2025-08-03T14:38:37.233592Z"
    }
   },
   "source": [
    "def set_seed(seed=42, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b2ba7f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.249076Z",
     "start_time": "2025-08-03T14:38:37.243796Z"
    }
   },
   "source": [
    "set_seed(42)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "4407a4a8",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271bc4c",
   "metadata": {},
   "source": [
    "We define a dataset to create the parity sequences for training and testing. Each sample is a sequence of length `sequence_length`, where we randomly place -1s and 1s at each position. We calculate the target sequence (of the same length) as the parity upto and including that position, with 0s corresponding to negative parity and 1s corrsponding to positive parity."
   ]
  },
  {
   "cell_type": "code",
   "id": "830313fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.256447Z",
     "start_time": "2025-08-03T14:38:37.254157Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39ec4d00",
   "metadata": {},
   "source": [
    "We set the parity sequence length to `grid_size ** 2 = 16`, and prepare the train and test loaders. We use a `batch_size` of 64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069121b9",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d91d78",
   "metadata": {},
   "source": [
    "Next we define the loss function. First, for all internal ticks of the CTM, we calculate the cross-entropy loss for all positions along the output sequence. Then, as with the other experiments, we only use the loss at two specific internal ticks: where the loss is the lowest and where the model is most certain. We use advanced indexing into the losses tensor to extract these losses, and then average them."
   ]
  },
  {
   "cell_type": "code",
   "id": "63e75f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.265968Z",
     "start_time": "2025-08-03T14:38:37.261651Z"
    }
   },
   "source": [
    "def reconstruction_loss(predictions, certainties, targets, use_most_certain=False):\n",
    "    \"\"\"\n",
    "    为时序重建任务计算损失，模仿原始图像分类损失的逻辑。\n",
    "\n",
    "    Args:\n",
    "        predictions (torch.Tensor): CTM的输出，形状为 (B, T*C, iterations)\n",
    "        certainties (torch.Tensor): CTM的确定性度量，形状为 (B, 2, iterations)\n",
    "        targets (torch.Tensor): 目标重建序列，形状为 (B, T, C)\n",
    "        use_most_certain (bool): True表示选择最确定的步骤，False表示选择最后一步。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 计算出的标量损失值。\n",
    "        torch.Tensor: 被选择用于计算loss_selected的步骤索引。\n",
    "    \"\"\"\n",
    "    B, T, C, iterations = predictions.shape\n",
    "    _B, T, C = targets.shape\n",
    "\n",
    "    # 将预测和目标调整为可比较的形状\n",
    "    # predictions: (B, T*C, iterations) -> (B, T, C, iterations)\n",
    "    # predictions_reshaped = predictions.view(B, T, C, iterations)\n",
    "    # targets: (B, T, C) -> (B, T, C, iterations)\n",
    "    targets_expanded = targets.unsqueeze(-1).repeat(1,1,1,iterations)\n",
    "\n",
    "    # 计算每个“思考”步骤的MSE损失\n",
    "    mse = nn.MSELoss(reduction='none')(predictions, targets_expanded)\n",
    "    # 在时间和通道维度上求平均，得到每个batch和每个iteration的损失\n",
    "    # losses: (B, iterations)\n",
    "    losses = mse.mean(dim=(1, 2))\n",
    "\n",
    "    # --- 模仿原始损失函数的逻辑 ---\n",
    "    # 1. 找到每个batch中，损失最小的那个“思考”步骤\n",
    "    loss_index_min_mse = losses.argmin(dim=1)\n",
    "\n",
    "    # 2. 根据确定性或默认选择最后一个步骤\n",
    "    if use_most_certain:\n",
    "        # certainties[:, 1] 是 1-entropy，值越大越确定\n",
    "        loss_index_selected = certainties[:, 1].argmax(dim=1)\n",
    "    else:\n",
    "        # 选择最后一个步骤\n",
    "        loss_index_selected = torch.tensor([iterations - 1] * B, device=predictions.device)\n",
    "\n",
    "    # 使用索引器获取对应的损失值\n",
    "    batch_indexer = torch.arange(B, device=predictions.device)\n",
    "\n",
    "    loss_min = losses[batch_indexer, loss_index_min_mse].mean()\n",
    "    loss_selected = losses[batch_indexer, loss_index_selected].mean()\n",
    "\n",
    "    # 将两个损失平均，作为最终损失\n",
    "    final_loss = (loss_min + loss_selected) / 2\n",
    "\n",
    "    return final_loss, loss_index_selected"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "a712a9a9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb8dd7",
   "metadata": {},
   "source": [
    "We define some helper functions for making the progress bar look pretty, and to display the training curves."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.275864Z",
     "start_time": "2025-08-03T14:38:37.271579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_pbar_desc(train_loss, test_loss, lr, where_most_certain):\n",
    "    \"\"\"A helper function to create a description for the tqdm progress bar\"\"\"\n",
    "    pbar_desc = f'Train Loss={train_loss:0.3f}. Test Loss={test_loss:0.3f}. LR={lr:0.6f}.'\n",
    "    pbar_desc += f' Where_certain={where_most_certain.float().mean().item():0.2f}+-{where_most_certain.float().std().item():0.2f} ({where_most_certain.min().item():d}<->{where_most_certain.max().item():d}).'\n",
    "    return pbar_desc\n",
    "\n",
    "def update_training_curve_plot(fig, ax1, ax2, train_losses, test_losses, steps):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Plot loss\n",
    "    ax1.clear()\n",
    "    ax1.plot(range(len(train_losses)), train_losses, 'b-', alpha=0.7, label=f'Train Loss: {train_losses[-1]:.3f}')\n",
    "    ax1.plot(steps, test_losses, 'r-', marker='o', label=f'Test Loss: {test_losses[-1]:.3f}')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot accuracy\n",
    "    # ax2.clear()\n",
    "    # ax2.plot(range(len(train_accuracies)), train_accuracies, 'b-', alpha=0.7, label=f'Train Accuracy: {train_accuracies[-1]:.3f}')\n",
    "    # ax2.plot(steps, test_accuracies, 'r-', marker='o', label=f'Test Accuracy: {test_accuracies[-1]:.3f}')\n",
    "    # ax2.set_title('Accuracy')\n",
    "    # ax2.set_xlabel('Step')\n",
    "    # ax2.set_ylabel('Accuracy')\n",
    "    # ax2.legend()\n",
    "    # ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    display(fig)"
   ],
   "id": "cd519bb4a90fa739",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "71541842",
   "metadata": {},
   "source": [
    "We then write the function to train the CTM."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.289829Z",
     "start_time": "2025-08-03T14:38:37.281520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Exp_Anomaly_Detection():\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Anomaly_Detection, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "\n",
    "    def train(self, model, device='cuda', training_iterations=10000, test_every=1000, lr=1e-4, log_dir='./logs'):\n",
    "\n",
    "        train_data, train_loader = self._get_data(flag='train')\n",
    "        vali_data, vali_loader = self._get_data(flag='val')\n",
    "        # test_data, test_loader = self._get_data(flag='test')\n",
    "\n",
    "\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "        model.train()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "        iterator = iter(train_loader)\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        steps = []\n",
    "\n",
    "        plt.ion()\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        with tqdm(total=training_iterations) as pbar:\n",
    "            for stepi in range(training_iterations):\n",
    "\n",
    "                try:\n",
    "                    x,_ = next(iterator)\n",
    "                except StopIteration:\n",
    "                    iterator = iter(train_loader)\n",
    "                    x,_ = next(iterator)\n",
    "\n",
    "                x = x.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                predictions_raw, certainties, _ = model(x)\n",
    "                B, _, iterations = predictions_raw.shape\n",
    "                _,T, C = x.shape\n",
    "                # Reshape: (B, SeqLength, C, T)\n",
    "                predictions = predictions_raw.view(B, T, C, iterations)\n",
    "\n",
    "                train_loss, where_most_certain = reconstruction_loss(predictions, certainties, x, use_most_certain=False)\n",
    "\n",
    "\n",
    "                # train_accuracy = (predictions.argmax(2)[torch.arange(predictions.size(0), device=predictions.device), :, where_most_certain] == x).float().mean().item()\n",
    "\n",
    "                train_losses.append(train_loss.item())\n",
    "                # train_accuracies.append(train_accuracy)\n",
    "\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if stepi % test_every == 0 or stepi == 0:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        all_test_predictions = []\n",
    "                        all_test_targets = []\n",
    "                        all_test_where_most_certain = []\n",
    "                        all_test_losses = []\n",
    "\n",
    "                        for x,_ in vali_loader:\n",
    "                            x = x.to(device)\n",
    "\n",
    "                            predictions_raw, certainties, where_most_certain = model(x)\n",
    "                            B, _, iterations = predictions_raw.shape\n",
    "                            _,T, C = x.shape\n",
    "                            # Reshape: (B, SeqLength, C, T)\n",
    "                            predictions = predictions_raw.view(B, T, C, iterations)\n",
    "\n",
    "                            test_loss, where_most_certain = reconstruction_loss(predictions, certainties, x, use_most_certain=False)\n",
    "                            all_test_losses.append(test_loss.item())\n",
    "                            all_test_predictions.append(predictions)\n",
    "                            all_test_targets.append(x)\n",
    "                            all_test_where_most_certain.append(where_most_certain)\n",
    "\n",
    "                        # test_accuracy = (all_test_predictions.argmax(2)[torch.arange(all_test_predictions.size(0), device=predictions.device), :, all_test_where_most_certain] == all_test_targets).float().mean().item()\n",
    "                        test_loss = sum(all_test_losses) / len(all_test_losses)\n",
    "\n",
    "                        test_losses.append(test_loss)\n",
    "                        # test_accuracies.append(test_accuracy)\n",
    "                        steps.append(stepi)\n",
    "\n",
    "                        # create_recon_gif_visualization(model, vali_loader, device, log_dir)\n",
    "\n",
    "                    model.train()\n",
    "\n",
    "                    update_training_curve_plot(fig, ax1, ax2, train_losses, test_losses, steps)\n",
    "\n",
    "                pbar_desc = make_pbar_desc(train_loss=train_loss.item(), test_loss=test_loss, lr=optimizer.param_groups[-1][\"lr\"], where_most_certain=where_most_certain)\n",
    "                pbar.set_description(pbar_desc)\n",
    "                pbar.update(1)\n",
    "\n",
    "        plt.ioff()\n",
    "        plt.close(fig)\n",
    "\n",
    "        return model\n",
    "\n"
   ],
   "id": "ef6c703720160b17",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "   def create_recon_gif_visualization(self, model, vali_loader, device, log_dir):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs_viz, targets_viz = next(iter(vali_loader))\n",
    "            inputs_viz = inputs_viz.to(device)\n",
    "            targets_viz = targets_viz.to(device)\n",
    "\n",
    "            predictions_raw, certainties, _, pre_activations, post_activations, attention = model(inputs_viz, track=True)\n",
    "\n",
    "            # Reshape predictions\n",
    "            predictions = predictions_raw.reshape(predictions_raw.size(0), -1, 2, predictions_raw.size(-1))\n",
    "\n",
    "            attention = reshape_attention_weights(attention)\n",
    "            inputs = reshape_inputs(inputs_viz, 50, grid_size=grid_size)\n",
    "\n",
    "            # Generate the parity GIF\n",
    "            make_parity_gif(\n",
    "                predictions.detach().cpu().numpy(),\n",
    "                certainties.detach().cpu().numpy(),\n",
    "                targets_viz.detach().cpu().numpy(),\n",
    "                pre_activations,\n",
    "                post_activations,\n",
    "                attention,\n",
    "                inputs,\n",
    "                f'{log_dir}/prediction.gif',\n",
    "            )\n",
    "\n",
    "            predictions_raw, certainties, _ = model(inputs_viz)\n",
    "            predictions = predictions_raw.reshape(predictions_raw.size(0), -1, 2, predictions_raw.size(-1))"
   ],
   "id": "52d604a6d192ae55"
  },
  {
   "cell_type": "markdown",
   "id": "67e6c8fc",
   "metadata": {},
   "source": "### Initialzing the CTM"
  },
  {
   "cell_type": "markdown",
   "id": "7a9cac52",
   "metadata": {},
   "source": [
    "Next we initialize the CTM. There are three important arguments to highlight for this task, which differ from, for example, the image classification task.\n",
    "\n",
    "- `backbone_type = 'parity_backbone'`: the backbone type `'parity_backbone'`, which is defined in the CTM repo, is a learned embedding layer which embeds the binary values in the input sequence.\n",
    "- `positional_embedding_type = 'custom-rotational-1d'`: a positional embedding for each position in the parity sequence. These positional embeddings are added to the embedding vectors (produced by the backbone) during the forward pass.\n",
    "- `prediction_reshaper = [parity_sequence_length, 2]`: the CTM has an optional argument `prediction_reshaper`. This is required when the output of the model is a sequence. For instance, it is required here where the output is a sequence of parities, or in the maze task where the output is a sequence of actions. This prediction reshaper is used in each internal tick of the CTM when the certainty of the models output is computed. Generally, the prediction reshaper should be like `[SEQUENCE_LENGTH, NUM_CLASS]`."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.300589Z",
     "start_time": "2025-08-03T14:38:37.295650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CTMForReconstruction(nn.Module):\n",
    "    \"\"\"\n",
    "    一个封装了CTM的模块，专门用于时序重建任务。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_timesteps: int,\n",
    "                 input_channels: int,\n",
    "                 d_backbone: int,\n",
    "                 ctm_args: dict):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_timesteps (int): 输入序列的时间步长 (T)。\n",
    "            input_channels (int): 输入序列的通道数 (C)。\n",
    "            d_backbone (int): 时序backbone输出的特征维度。\n",
    "            ctm_args (dict): 用于初始化原始ContinuousThoughtMachine的参数字典。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_timesteps = input_timesteps\n",
    "        self.input_channels = input_channels\n",
    "\n",
    "        # 1. 初始化时序Backbone\n",
    "        self.backbone = TemporalBackbone(input_channels, d_backbone, input_timesteps)\n",
    "\n",
    "        # 2. 初始化1D位置编码\n",
    "        # CTM代码中已提供，这里直接使用\n",
    "        self.positional_embedding = CustomRotationalEmbedding1D(d_backbone)\n",
    "\n",
    "        # 3. 准备CTM的参数\n",
    "        # 强制设置一些参数以适应新任务\n",
    "        ctm_args['backbone_type'] = 'none'  # 我们使用自己的backbone\n",
    "        ctm_args['positional_embedding_type'] = 'none'  # 我们在外部处理位置编码\n",
    "        ctm_args['d_input'] = d_backbone  # CTM的输入维度是backbone的输出维度\n",
    "        # 输出维度必须等于 T * C 以便重建\n",
    "        ctm_args['out_dims'] = input_timesteps * input_channels\n",
    "        # prediction_reshaper用于计算确定性，也需要更新\n",
    "        ctm_args['prediction_reshaper'] = [input_timesteps, input_channels]\n",
    "\n",
    "        # 4. 初始化CTM核心\n",
    "        self.ctm = ContinuousThoughtMachine(**ctm_args)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, track: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入时序数据，形状为 (B, T, C)\n",
    "            track (bool): 是否追踪CTM内部状态。\n",
    "\n",
    "        Returns:\n",
    "            Tuple: (predictions, certainties, ...) CTM的原始输出\n",
    "        \"\"\"\n",
    "        # x shape: (B, T, C)\n",
    "\n",
    "        # Conv1d期望输入 (B, C, T)，所以需要置换维度\n",
    "        x_permuted = x.permute(0, 2, 1)  # -> (B, C, T)\n",
    "\n",
    "        # 1. 通过时序Backbone提取特征\n",
    "        features = self.backbone(x_permuted)  # -> (B, d_backbone, T)\n",
    "\n",
    "        # 2. 添加1D位置编码\n",
    "        pos_emb = self.positional_embedding(features)  # -> (B, d_backbone, T)\n",
    "        combined_features = features + pos_emb\n",
    "\n",
    "        # 3. 将特征维度调整为CTM期望的 (B, SeqLen, FeatDim)\n",
    "        # kv_features: (B, T, d_backbone)\n",
    "        kv_features = combined_features.transpose(1, 2)\n",
    "\n",
    "        # 4. 调用CTM核心的forward方法，并传入预计算的kv特征\n",
    "        # kv_proj和q_proj会处理从d_backbone到d_input的投影\n",
    "        # 我们在__init__中设置了d_input=d_backbone，所以这里维度是匹配的\n",
    "        outputs = self.ctm(x=None, track=track, precomputed_kv=kv_features)\n",
    "\n",
    "        return outputs\n"
   ],
   "id": "74c66474b869ff42",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "2c180995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:38:37.392221Z",
     "start_time": "2025-08-03T14:38:37.306291Z"
    }
   },
   "source": [
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# 任务相关参数\n",
    "BATCH_SIZE = 4\n",
    "INPUT_TIMESTEPS = 100 # 例如，100个时间步\n",
    "INPUT_CHANNELS = 20   # 例如，每个时间步有10个特征\n",
    "D_BACKBONE = 64       # 我们的时序backbone输出的特征维度\n",
    "\n",
    "# CTM核心参数 (根据您的需要进行调整)\n",
    "ctm_parameters = {\n",
    "    'iterations': 16,\n",
    "    'd_model': 256,\n",
    "    'd_input': D_BACKBONE, # 这个值会被重写，但最好保持一致\n",
    "    'heads': 4,\n",
    "    'n_synch_out': 128,\n",
    "    'n_synch_action': 64,\n",
    "    'synapse_depth': 2,\n",
    "    'memory_length': 16,\n",
    "    'deep_nlms': True,\n",
    "    'memory_hidden_dims': 32,\n",
    "    'do_layernorm_nlm': False,\n",
    "    'dropout': 0.1,\n",
    "    'neuron_select_type': 'random-pairing',\n",
    "}\n",
    "class Args:\n",
    "   def __init__(self, dictionary):\n",
    "       for key, value in dictionary.items():\n",
    "           setattr(self, key, value)\n",
    "args = Args({\n",
    "    'batch_size' : BATCH_SIZE,\n",
    "    'device': device,\n",
    "    'seq_len': INPUT_TIMESTEPS,\n",
    "    'data': 'BSM',\n",
    "    'num_workers': 1,\n",
    "    'task_name': 'anomaly_detection',\n",
    "    'root_path': '../dataset/BSM'\n",
    "})\n",
    "\n",
    "# Define the model\n",
    "# 使用封装类来创建模型\n",
    "model = CTMForReconstruction(\n",
    "    input_timesteps=INPUT_TIMESTEPS,\n",
    "    input_channels=INPUT_CHANNELS,\n",
    "    d_backbone=D_BACKBONE,\n",
    "    ctm_args=ctm_parameters\n",
    ").to(device)\n",
    "\n",
    "# Initialize model parameters with dummy forward pass\n",
    "# dummy_input = torch.randn(BATCH_SIZE, INPUT_TIMESTEPS, INPUT_CHANNELS).to(device)\n",
    "# dummy_target = dummy_input.clone() + torch.randn_like(dummy_input) * 0.1 # 模拟一个重建目标\n",
    "#\n",
    "# # 前向传播\n",
    "# predictions, certainties, _ = model(dummy_input)\n",
    "#\n",
    "# print(f\"\\n输入形状: {dummy_input.shape}\")\n",
    "# print(f\"预测输出形状: {predictions.shape}\") # 应该是 (B, T*C, iterations)\n",
    "# print(f\"确定性输出形状: {certainties.shape}\") # 应该是 (B, 2, iterations)\n",
    "#\n",
    "# # print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "#\n",
    "# loss, selected_indices = reconstruction_loss(predictions, certainties, dummy_target, use_most_certain=True)\n",
    "#\n",
    "# print(f\"\\n计算出的重建损失: {loss.item():.4f}\")\n",
    "# print(f\"用于计算 'loss_selected' 的步骤索引: {selected_indices.tolist()}\")\n",
    "#\n",
    "# # 梯度回传\n",
    "# loss.backward()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using neuron select type: random-pairing\n",
      "Synch representation size action: 64\n",
      "Synch representation size out: 128\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exp = Exp_Anomaly_Detection(args)\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "print(f\"当前工作目录：{current_dir}\")\n",
    "model = exp.train(model=model, device=device, training_iterations=20, lr=1e-4, log_dir='./recon_logs')"
   ],
   "id": "b242fe210bfc05de",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15352\\AppData\\Local\\Temp\\ipykernel_45332\\375097109.py:4: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1831.)\n",
      "  pbar_desc += f' Where_certain={where_most_certain.float().mean().item():0.2f}+-{where_most_certain.float().std().item():0.2f} ({where_most_certain.min().item():d}<->{where_most_certain.max().item():d}).'\n",
      "Train Loss=0.710. Test Loss=1.439. LR=0.000100. Where_certain=11.00+-7.35 (0<->15).: 100%|██████████| 20/20 [01:12<00:00,  3.63s/it] \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cbd9b",
   "metadata": {},
   "source": [
    "Visualise a gif of a solution"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T14:39:54.573788Z",
     "start_time": "2025-08-03T14:39:54.571533Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3c5436dbab56bed1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
